{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ebl6h_dDe8UO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwsu2UQswAKX",
        "outputId": "774d138b-315a-4628-dc62-b51b7b587d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Diplomski/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiJ8j3BgwUhD",
        "outputId": "529bd0b7-7c6f-40c9-d439-a1d39befc08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Diplomski\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvcNUhd7agEG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import Image  # for displaying images\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(108)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test/Val"
      ],
      "metadata": {
        "id": "pBNryDeMPEs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read images and annotations, split into train-test\n",
        "\n",
        "images=[os.path.join('/content/drive/MyDrive/Diplomski/yolov5/data/Moxa3K/images',x) for x in os.listdir('/content/drive/MyDrive/Diplomski/yolov5/data/Moxa3K/images')]\n",
        "annotations=[os.path.join('/content/drive/MyDrive/Diplomski/yolov5/data/Moxa3K/annotations',x) for x in os.listdir('/content/drive/MyDrive/Diplomski/yolov5/data/Moxa3K/annotations')]\n",
        "images.sort()\n",
        "annotations.sort()\n",
        "train_images, test20_images, train_annotations, test20_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n"
      ],
      "metadata": {
        "id": "iFVaA8vMbeLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train-valid-test splits\n",
        "train_images, test20_images, train_annotations, test20_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n"
      ],
      "metadata": {
        "id": "_cYhbEeJdhy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "547ZrA1VQZxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utility function to move images\n",
        "def move_files_to_folder(list_of_files, destination_folder):\n",
        "    for f in list_of_files:\n",
        "        try:\n",
        "            shutil.move(f, destination_folder)\n",
        "        except:\n",
        "            print(f)\n",
        "\n",
        "# Move the splits into their folders\n",
        "move_files_to_folder(train_images, '/content/drive/MyDrive/Diplomski/yolov5/data/Data/train')\n",
        "move_files_to_folder(test20_images, '/content/drive/MyDrive/Diplomski/yolov5/data/Data/test20/images')\n",
        "move_files_to_folder(train_annotations, '/content/drive/MyDrive/Diplomski/yolov5/data/Data/train')\n",
        "move_files_to_folder(test20_annotations, '/content/drive/MyDrive/Diplomski/yolov5/data/Data/test20/annotations')\n"
      ],
      "metadata": {
        "id": "kAAOmXExe3t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split test20 into test and val\n",
        "test_images, val_images, test_annotations, val_annotations = train_test_split(test20_images, test20_annotations, test_size = 0.5, random_state = 1)\n",
        "move_files_to_folder(test_images, '/content/drive/MyDrive/Diplomski/yolov5/data/Data/test')\n",
        "move_files_to_folder(val_images, '/content/drive/MyDrive/Diplomski/yolov5/data/Data/val')\n",
        "move_files_to_folder(test_annotations, '/content/drive/MyDrive/Diplomski/yolov5/data/Data/test')\n",
        "move_files_to_folder(val_annotations, '/content/drive/MyDrive/Diplomski/yolov5/data/Data/val')\n"
      ],
      "metadata": {
        "id": "9n4tXVuOgPam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistika"
      ],
      "metadata": {
        "id": "vJy24TrbO-eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {}\n",
        "\n",
        "for folder in ['test']:\n",
        "  for file in os.listdir(folder):\n",
        "    if '.jpg' in file:\n",
        "      picture_name = file[:-4]\n",
        "      image = PIL.Image.open(os.getcwd()+f'/{folder}/'+picture_name+'.jpg')\n",
        "      image = cv2.imread(os.getcwd()+f'/{folder}/'+picture_name+'.jpg')\n",
        "      height, width, _ = image.shape\n",
        "      d[picture_name] = {}\n",
        "      d[picture_name]['width'] = int(width)\n",
        "      d[picture_name]['height'] = int(height)\n",
        "      d[picture_name]['area'] = height*width\n",
        "\n",
        "      with open(os.getcwd()+f'/{folder}/'+picture_name+'.txt', 'r') as f:\n",
        "        lbl_list = []\n",
        "        for line in f.readlines():\n",
        "          lbl_data = line.split()\n",
        "          lbl_dict = {}\n",
        "          lbl_dict['class'] = lbl_data[0]\n",
        "          lbl_dict['x'] = float(lbl_data[1]) * width # x,y, width i height su\n",
        "          lbl_dict['y'] = float(lbl_data[2]) * height # proporcije u odnosu na sliku\n",
        "          lbl_dict['width'] = float(lbl_data[3]) * width # pa mnoÅ¾imo sa\n",
        "          lbl_dict['height'] = float(lbl_data[4]) * height # dimenzijama slike\n",
        "          lbl_dict['area'] = lbl_dict['width'] * lbl_dict['height']\n",
        "\n",
        "          lbl_list.append(lbl_dict)\n",
        "        d[picture_name]['labels'] = lbl_list\n",
        "        if len(d) % 10 == 0:\n",
        "          print(len(d))"
      ],
      "metadata": {
        "id": "LiJ1dUs1SCU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "X6PEBrN-TFVs",
        "outputId": "c7300ee9-8487-4efd-f940-bf7724040eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Diplomski/Data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_num = 3000\n",
        "d = {}\n",
        "\n",
        "for i in range(img_num):\n",
        "  picture_name = 'MOXA_'+str(i)\n",
        "  image=PIL.Image.open(os.getcwd()+f'/{folder}/'+picture_name+'.jpg')\n",
        "  width, height = image.size\n",
        "  d[picture_name] = {}\n",
        "  d[picture_name]['width'] = int(width)\n",
        "  d[picture_name]['height'] = int(height)\n",
        "  d[picture_name]['area'] = height*width\n",
        "  with open(os.getcwd()+f'/{folder}/'+picture_name+'.txt','r') as f:\n",
        "    lbl_list = []\n",
        "    for line in f.readlines():\n",
        "      lbl_data = line.split()\n",
        "      lbl_dict = {}\n",
        "      lbl_dict['class'] = lbl_data[0]\n",
        "      lbl_dict['x'] = float(lbl_data[1]) * width # x,y, width i height su\n",
        "      lbl_dict['y'] = float(lbl_data[2]) * height # proporcije u odnosu na sliku\n",
        "      lbl_dict['width'] = float(lbl_data[3]) * width # pa mnoÅ¾imo sa\n",
        "      lbl_dict['height'] = float(lbl_data[4]) * height # dimenzijama slike\n",
        "      lbl_dict['area'] = lbl_dict['width'] * lbl_dict['height']\n",
        "\n",
        "      lbl_list.append(lbl_dict)\n",
        "    d[picture_name]['labels'] = lbl_list\n",
        "\n"
      ],
      "metadata": {
        "id": "_Alg67Sbf-rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "for key, value in d.items():\n",
        "  for label in value['labels']:\n",
        "    label['picture'] = key\n",
        "    label['picture_width'] = value['width']\n",
        "    label['picture_height'] = value['height']\n",
        "    label['picture_area'] = value['area']\n",
        "    l.append(label)\n",
        "df = pd.DataFrame(l)\n",
        "\n"
      ],
      "metadata": {
        "id": "8OpVtcY4rIEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe() # Osnovni statisticki podaci"
      ],
      "metadata": {
        "id": "52ebwA97rqb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLOv5\n"
      ],
      "metadata": {
        "id": "hMb34CXuQzHU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-Pz6q7DL9am",
        "outputId": "08f8d89d-2879-4529-990f-ef2229c97bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xINBTXxQMkOX",
        "outputId": "3df55ab2-2898-41ae-9075-757273f3a06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Diplomski/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr requirements.txt"
      ],
      "metadata": {
        "id": "czL8RLmaMr07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06deb710-63eb-451d-fba4-d5fba56179ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m617.0/617.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56KDat1dMxtG",
        "outputId": "8503ef3e-fda9-4dce-acf9-dde7b21513cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-217-g8c45e51 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clearml"
      ],
      "metadata": {
        "id": "mFoc4y39NQhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!clearml-init"
      ],
      "metadata": {
        "id": "s71ThmhJO5yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Face mask detection"
      ],
      "metadata": {
        "id": "QQFhlAx7RTxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 20 --data MOXA_colab.yaml --weights yolov5l.pt --cache --save-period 5"
      ],
      "metadata": {
        "id": "hhP0TZptPlZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 40 --data MOXA_colab.yaml --weights yolov5l.pt --cache --save-period 5 --optimizer Adam"
      ],
      "metadata": {
        "id": "wtvX1uBh7Vph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "g-8kY410RmqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp/weights/epoch5.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "_ZWEuY0pD5Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp/weights/epoch10.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "ikPOUM4MEX5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp/weights/epoch15.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "SJKB0v2nEYaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp/weights/last.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "CvkGCLAfEYyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp3/weights/epoch5.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "91cO9KgvEZWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp3/weights/epoch10.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "6YiwpWbkR_zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp3/weights/epoch15.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "yznEpo6lSBpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp3/weights/epoch20.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "gfY-MUzFSD5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp3/weights/epoch25.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "hQJI4VbZSIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp3/weights/epoch30.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "h8Bd2AYgSKUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp3/weights/epoch35.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "yypYbAK5SMnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights runs/train/exp3/weights/last.pt --data MOXA_colab.yaml --img 640 --task test --batch-size 1"
      ],
      "metadata": {
        "id": "H33G6HunSPQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FACE DETECTION"
      ],
      "metadata": {
        "id": "cGn7jKLfSTw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import uuid\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "6-LrDG9aSU-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as alb"
      ],
      "metadata": {
        "id": "oBY8Sg3kSnLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentor = alb.Compose([alb.RandomCrop(width=640, height=640),\n",
        "                         alb.HorizontalFlip(p=0.5),\n",
        "                         alb.RandomBrightnessContrast(p=0.2),\n",
        "                         alb.RandomGamma(p=0.2),\n",
        "                         alb.RGBShift(p=0.2),\n",
        "                         alb.VerticalFlip(p=0.5)],\n",
        "                       bbox_params=alb.BboxParams(format='albumentations',\n",
        "                                                  label_fields=['class_labels']))"
      ],
      "metadata": {
        "id": "hQyZl2ZKSn4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funkcija za ucitavanje slika\n",
        "def load_image(x):\n",
        "    byte_img = tf.io.read_file(x)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    return img"
      ],
      "metadata": {
        "id": "dQz7Qt9uSr3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for partition in ['train','test','val']:\n",
        "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
        "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
        "\n",
        "        coords = [0,0,0.00001,0.00001] #difoltni set koordinata\n",
        "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                label = json.load(f)\n",
        "\n",
        "            coords[0] = label['shapes'][0]['points'][0][0]\n",
        "            coords[1] = label['shapes'][0]['points'][0][1]\n",
        "            coords[2] = label['shapes'][0]['points'][1][0]\n",
        "            coords[3] = label['shapes'][0]['points'][1][1]\n",
        "            coords = list(np.divide(coords, [1280,720,1280,720]))\n",
        "\n",
        "        try:\n",
        "            for x in range(60):\n",
        "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
        "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
        "\n",
        "                annotation = {}\n",
        "                annotation['image'] = image\n",
        "\n",
        "                if os.path.exists(label_path):\n",
        "                    if len(augmented['bboxes']) == 0:\n",
        "                        annotation['bbox'] = [0,0,0,0]\n",
        "                        annotation['class'] = 0\n",
        "                    else:\n",
        "                        annotation['bbox'] = augmented['bboxes'][0]\n",
        "                        annotation['class'] = 1\n",
        "                else:\n",
        "                    annotation['bbox'] = [0,0,0,0] #ovo je deo za ako ne postoji klasa\n",
        "                    annotation['class'] = 0\n",
        "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
        "                    json.dump(annotation, f)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)"
      ],
      "metadata": {
        "id": "WTej0R8YSw8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = tf.data.Dataset.list_files('aug_data\\\\train\\\\images\\\\*.jpg', shuffle=False)\n",
        "train_images = train_images.map(load_image)\n",
        "train_images = train_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "train_images = train_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "vGLA_vWUS397"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = tf.data.Dataset.list_files('aug_data\\\\final\\\\images\\\\*.jpg', shuffle=False)\n",
        "final = final.map(load_image)\n",
        "final = final.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "final = final.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "ZSTE2xHeS-yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = tf.data.Dataset.list_files('aug_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
        "test_images = test_images.map(load_image)\n",
        "test_images = test_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "test_images = test_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "v_jgSkdKTC-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = tf.data.Dataset.list_files('aug_data\\\\val\\\\images\\\\*.jpg', shuffle=False)\n",
        "val_images = val_images.map(load_image)\n",
        "val_images = val_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "val_images = val_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "NGWQXs6ITFv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testMasks_images = tf.data.Dataset.list_files('aug_data\\\\testMasks\\\\images\\\\*.jpg', shuffle=False)\n",
        "testMasks_images = testMasks_images.map(load_image)\n",
        "testMasks_images = testMasks_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
        "testMasks_images = testMasks_images.map(lambda x: x/255)"
      ],
      "metadata": {
        "id": "apS5IWXeTH_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels(label_path):\n",
        "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
        "        label = json.load(f)\n",
        "\n",
        "    return [label['class']], label['bbox'] #vracamo klasu i bounding box koorinate, class je 0 ili 1"
      ],
      "metadata": {
        "id": "EhP_M6ijTMkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_labels = tf.data.Dataset.list_files('aug_data\\\\final\\\\labels\\\\*.json', shuffle=False)\n",
        "final_labels = final_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
      ],
      "metadata": {
        "id": "dnaWMMRITNGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
        "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
      ],
      "metadata": {
        "id": "s6sDjR3XTPcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
        "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
      ],
      "metadata": {
        "id": "qjt-ak7WTSAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testMasks_labels = tf.data.Dataset.list_files('aug_data\\\\testMasks\\\\labels\\\\*.json', shuffle=False)\n",
        "testMasks_labels = testMasks_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16])"
      ],
      "metadata": {
        "id": "ZzLA54f6TalW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels = tf.data.Dataset.list_files('aug_data\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
        "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
      ],
      "metadata": {
        "id": "nkIdpmg2TctN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = tf.data.Dataset.zip((train_images, train_labels))\n",
        "train = train.shuffle(5000)\n",
        "train = train.batch(8)\n",
        "train = train.prefetch(4)"
      ],
      "metadata": {
        "id": "zSKsA8CrTh_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = tf.data.Dataset.zip((test_images, test_labels))\n",
        "test = test.shuffle(1300)\n",
        "test = test.batch(8)\n",
        "test = test.prefetch(4)"
      ],
      "metadata": {
        "id": "ts8oCcBDTlus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testMask = tf.data.Dataset.zip((testMasks_images, testMasks_labels))\n",
        "testMask = testMask.shuffle(1300)\n",
        "testMask = testMask.batch(8)\n",
        "testMask = testMask.prefetch(4)"
      ],
      "metadata": {
        "id": "N2ZaOxN3TpOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = tf.data.Dataset.zip((val_images, val_labels))\n",
        "val = val.shuffle(1000)\n",
        "val = val.batch(8)\n",
        "val = val.prefetch(4)"
      ],
      "metadata": {
        "id": "LJXJvtOeTrDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16"
      ],
      "metadata": {
        "id": "MmGK7JATTxex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
        "from tensorflow.keras.applications import VGG16"
      ],
      "metadata": {
        "id": "kmnFBGZiTwBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(include_top=False)"
      ],
      "metadata": {
        "id": "hbYxCKm5T4Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    input_layer = Input(shape=(120,120,3))\n",
        "    #naseg inputa\n",
        "\n",
        "    vgg = VGG16(include_top=False)(input_layer)\n",
        "\n",
        "    # Classification Model\n",
        "    f1 = GlobalMaxPooling2D()(vgg)\n",
        "    class1 = Dense(2048, activation='relu')(f1)\n",
        "    class2 = Dense(1, activation='sigmoid')(class1)\n",
        "\n",
        "\n",
        "    # Bounding box model\n",
        "    f2 = GlobalMaxPooling2D()(vgg)\n",
        "    regress1 = Dense(2048, activation='relu')(f2)\n",
        "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
        "\n",
        "    facetracker = Model(inputs=input_layer, outputs=[class2, regress2])\n",
        "    return facetracker"
      ],
      "metadata": {
        "id": "QkPuld4ET7dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches_per_epoch = len(train)\n",
        "lr_decay = (1./0.75 -1)/batches_per_epoch"
      ],
      "metadata": {
        "id": "c4xPa-uKUHuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_learning_rate = 0.0001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=10000, decay_rate=lr_decay\n",
        ")"
      ],
      "metadata": {
        "id": "_J9AOEh4UIP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule) #adam optimizer"
      ],
      "metadata": {
        "id": "jTb9KM5rUKW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def localization_loss(y_true, yhat):\n",
        "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2]))\n",
        "\n",
        "    h_true = y_true[:,3] - y_true[:,1]\n",
        "    w_true = y_true[:,2] - y_true[:,0] #actual width of the box\n",
        "\n",
        "    h_pred = yhat[:,3] - yhat[:,1] #predicted high of the box\n",
        "    w_pred = yhat[:,2] - yhat[:,0] #predicted with of the box\n",
        "\n",
        "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
        "\n",
        "    return delta_coord + delta_size"
      ],
      "metadata": {
        "id": "XMrK19vXUMnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traing"
      ],
      "metadata": {
        "id": "2Ho_DM_JUV3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceTracker(Model):\n",
        "\n",
        "    def __init__(self, eyetracker,  **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model = eyetracker\n",
        "\n",
        "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.closs = classloss\n",
        "        self.lloss = localizationloss\n",
        "        self.opt = opt\n",
        "\n",
        "    def train_step(self, batch, **kwargs):\n",
        "\n",
        "        X, y = batch\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            classes, coords = self.model(X, training=True)\n",
        "\n",
        "            batch_classloss = self.closs(y[0], classes)\n",
        "            batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
        "\n",
        "            total_loss = batch_localizationloss+0.5*batch_classloss\n",
        "\n",
        "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
        "\n",
        "        opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
        "\n",
        "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
        "\n",
        "\n",
        "    def test_step(self, batch, **kwargs):\n",
        "        X, y = batch\n",
        "        classes, coords = self.model(X, training=False)\n",
        "\n",
        "        batch_classloss = self.closs(y[0], classes)\n",
        "        batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
        "        total_loss = batch_localizationloss + 0.5 * batch_classloss\n",
        "\n",
        "        # Calculate classification predictions\n",
        "        #predicted_labels = tf.argmax(classes, axis=-1)\n",
        "       # true_labels = tf.argmax(y[0], axis=-1)\n",
        "        predicted_labels = classes\n",
        "        true_labels = y[0]\n",
        "        threshold = 0.5\n",
        "        binary_predicted_labels = (predicted_labels > threshold).astype(int)\n",
        "\n",
        "        # Calculate metrics\n",
        "        precision = precision_score(true_labels, binary_predicted_labels, average='weighted')\n",
        "        recall = recall_score(true_labels, binary_predicted_labels, average='weighted')\n",
        "        f1 = f1_score(true_labels, binary_predicted_labels, average='weighted')\n",
        "\n",
        "        # Calculate IoU and Average Precision\n",
        "        predicted_bboxes = coords  # Assuming coords are bounding box predictions\n",
        "        true_bboxes = y[1]  # Assuming y[1] contains true bounding boxes\n",
        "        iou = calculate_iou(true_bboxes, predicted_bboxes)  # Modify to calculate IoU\n",
        "        ap = average_precision_score(true_labels, binary_predicted_labels, average='weighted')  # Calculate AP\n",
        "\n",
        "        return {\n",
        "            \"total_loss\":total_loss,\n",
        "            \"class_loss\":batch_classloss,\n",
        "            \"regress_loss\":batch_localizationloss,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1,\n",
        "            \"iou\": iou,\n",
        "            \"ap\": ap\n",
        "        }\n",
        "    def call(self, X, **kwargs):\n",
        "        return self.model(X, **kwargs)\n"
      ],
      "metadata": {
        "id": "hzd7g4SqUa3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "R-6AqZ_9Uo0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "iou_scores = []\n",
        "ap_scores = []\n",
        "\n",
        "# Iterate through test set and evaluate the model\n",
        "for epoch in range(10):\n",
        "    # ... (Code for model training here if needed)\n",
        "\n",
        "    # Initialize metrics for this epoch\n",
        "    total_precision = 0\n",
        "    total_recall = 0\n",
        "    total_f1 = 0\n",
        "    total_iou = 0\n",
        "    total_ap = 0\n",
        "\n",
        "    for batch in test:\n",
        "        images, labels = batch\n",
        "        predictions = model.predict(images)  # Assuming 'model' is your FaceTracker model\n",
        "\n",
        "        # Calculate IoU\n",
        "        #iou_metric = tf.keras.metrics.MeanIoU(num_classes=1)  # Set the number of classes\n",
        "\n",
        "        #labels_argmax = tf.argmax(labels, axis=-1, output_type=tf.uint8)\n",
        "        #predictions_argmax = tf.argmax(predictions, axis=-1, output_type=tf.uint8)\n",
        "\n",
        "        #iou_metric.update_state(labels_argmax, predictions_argmax)\n",
        "\n",
        "        #iou_value = iou_metric.result().numpy()\n",
        "        #total_iou += iou_value\n",
        "\n",
        "        # Flatten the predictions and labels for binary classification\n",
        "        flat_predictions = np.reshape(predictions[0], (-1,))\n",
        "        flat_labels = np.reshape(labels[0], (-1,))\n",
        "\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        precision = precision_score(flat_labels, (flat_predictions > 0.9).astype(int))\n",
        "        recall = recall_score(flat_labels, (flat_predictions > 0.9).astype(int))\n",
        "        f1 = f1_score(flat_labels, (flat_predictions > 0.9).astype(int))\n",
        "\n",
        "        total_precision += precision\n",
        "        total_recall += recall\n",
        "        total_f1 += f1\n",
        "        #total_iou += iou\n",
        "\n",
        "        # Calculate Average Precision\n",
        "        ap = average_precision_score(flat_labels, flat_predictions)\n",
        "        total_ap += ap\n",
        "\n",
        "    # Calculate averages for this epoch\n",
        "    avg_precision = total_precision / len(test)\n",
        "    avg_recall = total_recall / len(test)\n",
        "    avg_f1 = total_f1 / len(test)\n",
        "    #avg_iou = total_iou / len(test)\n",
        "    avg_ap = total_ap / len(test)\n",
        "\n",
        "    # Append values to lists\n",
        "    precision_scores.append(avg_precision)\n",
        "    recall_scores.append(avg_recall)\n",
        "    f1_scores.append(avg_f1)\n",
        "    #iou_scores.append(avg_iou)\n",
        "    ap_scores.append(avg_ap)\n",
        "\n",
        "    # Print metrics for this epoch\n",
        "    print(f\"Epoch {epoch + 1}:\")\n",
        "    print(f\"Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, F1: {avg_f1:.4f}\")\n",
        "   # print(f\"IoU: {avg_iou:.4f}, Avg Precision: {avg_ap:.4f}\")\n",
        "    print()\n",
        "\n",
        "# Visualize metrics\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 11), precision_scores, label='Precision')\n",
        "plt.plot(range(1, 11), recall_scores, label='Recall')\n",
        "plt.plot(range(1, 11), f1_scores, label='F1')\n",
        "plt.plot(range(1, 11), iou_scores, label='IoU')\n",
        "plt.plot(range(1, 11), ap_scores, label='Avg Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Evaluation Metrics Over 10 Epochs')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irLw4kYiU1zU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}